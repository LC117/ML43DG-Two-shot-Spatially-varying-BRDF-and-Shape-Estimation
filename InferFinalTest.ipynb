{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9c7fce8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyexr\n",
    "from matplotlib import pyplot as plt\n",
    "from src.model.shape_model import ShapeNetwork\n",
    "from src.model.illumination_model import IlluminationNetwork\n",
    "from src.model.svbrdf_model import SVBRDF_Network\n",
    "from src.model.joint_model import JointNetwork\n",
    "from src.utils.visualize_tools import save_img\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8414965a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rgb(path : Path):\n",
    "    \"\"\"Read an image using Pillow\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : Path\n",
    "        File path.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    img : RGB or RGBA image in float32 format.\n",
    "    \"\"\"\n",
    "    image_ = Image.open(str(path))\n",
    "    img = np.array(image_.getdata(), dtype=np.float32)\n",
    "    img = img.reshape((256, 256, -1))\n",
    "    img = img[:, :, 0:3]\n",
    "    img = img / 255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "472e64c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mono(path : Path, ch=0):\n",
    "    \"\"\"Read an image using Pillow, return n-th channel\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : Path\n",
    "        File path.\n",
    "    ch   : int\n",
    "        optional channel id\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    channel : channel in float32 format\n",
    "    \"\"\"\n",
    "    channel = load_rgb(path)\n",
    "    channel = channel[..., ch]\n",
    "    return channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a6b0f82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = ShapeNetwork()\n",
    "model = ShapeNetwork.load_from_checkpoint(checkpoint_path=\"lightning_logs\\\\version_139\\\\checkpoints\\\\epoch=3-step=6187.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ed365958",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_sample[\"cam1\"] = torch.Tensor(test_sample[\"cam1\"][None, ...])\n",
    "#test_sample[\"cam2\"] = torch.Tensor(test_sample[\"cam2\"][None, ...])\n",
    "#test_sample[\"mask\"] = torch.Tensor(test_sample[\"mask\"][None, ...])\n",
    "cam1_path = Path(\"Test_Results/0/cam1.png\")\n",
    "cam2_path = Path(\"Test_Results/0/cam2.png\")\n",
    "mask_path = Path(\"Test_Results/0/mask.png\")\n",
    "cam1 = torch.Tensor(load_rgb(cam1_path)[None, ...]).permute((0, 3, 1, 2))\n",
    "cam2 = torch.Tensor(load_rgb(cam2_path)[None, ...]).permute((0, 3, 1, 2))\n",
    "mask = load_mono(mask_path)[None, None, ...]\n",
    "mask = torch.Tensor(np.where(np.less(mask, 0.9), np.zeros_like(mask), np.ones_like(mask)))\n",
    "normal, depth = model.forward((cam1, cam2, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "96000c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_path = \"Test_Results/Test/shape/\"\n",
    "\n",
    "save_img(depth, shape_path, \"depth\")\n",
    "save_img(normal, shape_path, \"normal\")\n",
    "save_img(mask, shape_path, \"mask\")\n",
    "save_img(cam1, shape_path, \"cam1\")\n",
    "save_img(cam2, shape_path, \"cam2\")\n",
    "\n",
    "\n",
    "#normal = normal.permute(0, 2, 3, 1).squeeze(0)\n",
    "#depth = depth.squeeze(0).squeeze(0)\n",
    "#normal = normal.detach().cpu().numpy()\n",
    "#depth = depth.detach().cpu().numpy()\n",
    "\n",
    "# create a new folder Test_Results\n",
    "# and save the depth and normal maps\n",
    "#if not os.path.exists(\"Test_Results/Test\"):\n",
    "#    os.makedirs(\"Test_Results/Test\")\n",
    "\n",
    "# save the depth map using matplotlib\n",
    "#plt.imsave(\"Test_Results/Test/depth.png\", depth, cmap=\"gray\", vmin=0, vmax=1)\n",
    "\n",
    "# save the normal map as rgb using matplotlib\n",
    "#plt.imsave(\"Test_Results/Test/normal.png\", normal)\n",
    "\n",
    "#cam1 = cam1.squeeze(0).permute((1, 2, 0)).detach().cpu().numpy()\n",
    "#cam2 = cam2.squeeze(0).permute((1, 2, 0)).detach().cpu().numpy()\n",
    "#mask = mask.detach().cpu().numpy().reshape(256, 256, 1)\n",
    "#plt.imsave(\"Test_Results/Test/cam1.png\", cam1)\n",
    "#plt.imsave(\"Test_Results/Test/cam2.png\", cam2)\n",
    "#plt.imsave(\"Test_Results/2/mask.png\", mask, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "45f32d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "illumination_model = IlluminationNetwork.load_from_checkpoint(checkpoint_path=\"lightning_logs\\\\version_155\\\\checkpoints\\\\epoch=7-step=12375.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2f87de77",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_illum = \"Test_Results/Test/illumination/\"\n",
    "\n",
    "sgs = illumination_model.forward((cam1, cam2, mask, normal, depth))\n",
    "\n",
    "# no saving here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a3396f35",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "apply_mask() missing 1 required positional argument: 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [69]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m svbrdf_model \u001b[38;5;241m=\u001b[39m SVBRDF_Network\u001b[38;5;241m.\u001b[39mload_from_checkpoint(checkpoint_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlightning_logs\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mversion_158\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mcheckpoints\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mepoch=2-step=4640.ckpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m path_svbrdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest_Results/Test/svbrdf/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m diffuse, specular, roughness \u001b[38;5;241m=\u001b[39m \u001b[43msvbrdf_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcam1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcam2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m save_img(diffuse, path_svbrdf, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiffuse\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m save_img(specular, path_svbrdf, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecular\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\Github\\Uni\\MS3-Git\\ML43DG\\Proj\\src\\model\\svbrdf_model.py:182\u001b[0m, in \u001b[0;36mSVBRDF_Network.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    179\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_conv2d_step(x)\n\u001b[0;32m    181\u001b[0m \u001b[38;5;66;03m# brdf_prediction:\u001b[39;00m\n\u001b[1;32m--> 182\u001b[0m diffuse \u001b[38;5;241m=\u001b[39m \u001b[43mapply_mask\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclamp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m specular \u001b[38;5;241m=\u001b[39m apply_mask(\n\u001b[0;32m    188\u001b[0m     torch\u001b[38;5;241m.\u001b[39mclamp(x[:, \u001b[38;5;241m3\u001b[39m:\u001b[38;5;241m6\u001b[39m, :, :], \u001b[38;5;241m40\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m1.0\u001b[39m),\n\u001b[0;32m    189\u001b[0m     mask\n\u001b[0;32m    190\u001b[0m )\n\u001b[0;32m    192\u001b[0m roughness \u001b[38;5;241m=\u001b[39m apply_mask(\n\u001b[0;32m    193\u001b[0m     torch\u001b[38;5;241m.\u001b[39mclamp(x[:, \u001b[38;5;241m6\u001b[39m:\u001b[38;5;241m7\u001b[39m, :, :], \u001b[38;5;241m0.004\u001b[39m, \u001b[38;5;241m1.0\u001b[39m),\n\u001b[0;32m    194\u001b[0m     mask\n\u001b[0;32m    195\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: apply_mask() missing 1 required positional argument: 'name'"
     ]
    }
   ],
   "source": [
    "svbrdf_model = SVBRDF_Network.load_from_checkpoint(checkpoint_path=\"lightning_logs\\\\version_158\\\\checkpoints\\\\epoch=2-step=4640.ckpt\")\n",
    "path_svbrdf = \"Test_Results/Test/svbrdf/\"\n",
    "\n",
    "diffuse, specular, roughness = svbrdf_model.forward((cam1, cam2, mask, normal, depth))\n",
    "\n",
    "save_img(diffuse, path_svbrdf, \"diffuse\")\n",
    "save_img(specular, path_svbrdf, \"specular\")\n",
    "save_img(roughness, path_svbrdf, \"roughness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255a2d22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
